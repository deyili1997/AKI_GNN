{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is only for encounter inclusion and exclusion, that is to say, the columns should not change after processing.  \n",
    "\n",
    "Encounters Inclusion and Exclusion Criteria:\n",
    "1. Age between 18 and 90.  \n",
    "2. Exclude patients with pre-existing end stage renal disease (ESRD), dialysis procedure or renal transplantation (RRT) prior to the visit.   \n",
    "3. Exclude patients who eGFR < 15 mL/min/1.73 m^2 or baseline SCr > 3.5 mg/dL.    \n",
    "4. SCr trajectories satisfy the requirements (at least one SCr measurement every day of the 3-day observation window).  \n",
    "5. Each ecnounter's AKI onset date is the most severe AKI stage onset date.  \n",
    "6. Only hospital-acquired AKI is considered, that is onset 48h after admission. |--Admission--|----Day-2----|-----AKI-----| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/lideyi/AKI_GNN/notebooks/utils\"))\n",
    "from common_var import raw_path, ct_names, pat_id_cols, race_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Record Table to Track Encounter Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_num_df = pd.DataFrame(0, index = ['Total number of encounters', \n",
    "                                          'Age between 18 and 90',\n",
    "                                          'Patients with ESRD, dialysis and RRT excluded',\n",
    "                                          'Patients with SCr baseline or eGFR out of range excluded',\n",
    "                                          'Only hospital-aquired AKI encounters',\n",
    "                                          'Encounters should be prior to 2020',\n",
    "                                          ], columns = ct_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in table to keep track of the number of encounters\n",
    "def fill_in_encounter_num_df(screen_item, ct_names, onset_df, encounter_num_df):\n",
    "    for ct_name in ct_names:\n",
    "        ct_enc_n = len(onset_df[onset_df.CENTER_NAME == ct_name])\n",
    "        print('%s: %s %d'%(ct_name, screen_item, ct_enc_n))\n",
    "        encounter_num_df.loc[screen_item, ct_name] = ct_enc_n\n",
    "    return encounter_num_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Patient ID DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_df = pd.read_csv('/blue/yonghui.wu/lideyi/AKI_GNN/raw_data/onset_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type formatting\n",
    "# all patid should be string\n",
    "onset_df[pat_id_cols] = onset_df[pat_id_cols].astype(str)\n",
    "# format date columns\n",
    "date_cols = ['ADMIT_DATE', 'DISCHARGE_DATE', 'AKI1_ONSET', 'AKI2_ONSET', 'AKI3_ONSET']\n",
    "for col in date_cols:\n",
    "    onset_df[col] = pd.to_datetime(onset_df[col], format = 'mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUMC: Total number of encounters 265222\n"
     ]
    }
   ],
   "source": [
    "encounter_num_df = fill_in_encounter_num_df('Total number of encounters', ct_names, onset_df, encounter_num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_dfs import read_and_format_DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_df = read_and_format_DEMO(ct_names, raw_path, race_mapping)\n",
    "# format type, we need SEX and RACE for eGFR calculation, thus we do not drop them here\n",
    "DEMO_df[pat_id_cols + ['SEX', 'RACE']] = DEMO_df[pat_id_cols + ['SEX', 'RACE']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the specified columns\n",
    "onset_df = onset_df.merge(DEMO_df, on=pat_id_cols, how = 'left')\n",
    "\n",
    "# all encounter should have demographics info\n",
    "assert(onset_df['AGE'].isna().mean() == 0)\n",
    "assert(onset_df['SEX'].isna().mean() == 0)\n",
    "assert(onset_df['RACE'].isna().mean() == 0)\n",
    "\n",
    "# Filter the merged DataFrame to find rows where 'AGE' < 18 or 'AGE' > 90\n",
    "onset_df = onset_df[(onset_df['AGE'] >= 18) & (onset_df['AGE'] < 90)]\n",
    "\n",
    "# If you want to reset the index of onset_df after dropping rows\n",
    "onset_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUMC: Age between 18 and 90 261691\n"
     ]
    }
   ],
   "source": [
    "encounter_num_df = fill_in_encounter_num_df('Age between 18 and 90', ct_names, onset_df, encounter_num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Diagnoses and Filter Encounters with ESRD, Dialysis and RRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the original read_and_format_DX, we have DX df merged with onset_df (patients to use MDRD in that case),\n",
    "#  however, it is too large here to be merged, thus we do it separately here\n",
    "from read_dfs import read_DX, concat_dfs_to_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESRD_dia_RRT_codes = {\n",
    "    '9': ['585.6', '39.93','39.95','54.98', 'V45.11', '55.51','55.52','55.53','55.54','55.61','55.69', 'V42.0'],\n",
    "    \n",
    "    '10': ['N18.6','5A1D00Z','5A1D60Z','5A1D70Z','5A1D80Z','5A1D90Z', 'Z99.2', '0TY00Z0','0TY00Z1','0TY00Z2',\n",
    "           '0TY10Z0','0TY10Z1','0TY10Z2','0TB00ZZ','0TB10ZZ','0TT00ZZ','0TT10ZZ','0TT20ZZ', 'Z94.0'],\n",
    "    \n",
    "    'CH': [str(cpt) for cpt in range(90935, 91000)] + \\\n",
    "        ['50300','50320','50323','50325','50327','50328','50329','50340','50360','50365','50370','50380']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lideyi/AKI_GNN/notebooks/utils/read_dfs.py:159: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  DX_df = pd.read_csv(data_path + \"AKI_DX.csv\", delimiter = ',')\n",
      "100%|██████████| 1/1 [00:35<00:00, 35.50s/it]\n"
     ]
    }
   ],
   "source": [
    "DX_dict = read_DX(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return encounters related to the input code dict\n",
    "def get_enc_by_DX_code(DX_dict: dict, pat_df: pd.DataFrame, \n",
    "                       code_dict: dict, code_types: list, pat_id_cols: list) -> dict:\n",
    "    processed_DX_dict = dict()\n",
    "    ct_missing_DX_DATE = ['UTHSCSA', 'UTSW', 'UofU']\n",
    "    \n",
    "    for ct_name, DX_df in tqdm(DX_dict.items()):\n",
    "        # format type\n",
    "        DX_df[['PATID', 'DX_TYPE', 'DX']] = DX_df[['PATID', 'DX_TYPE', 'DX']].astype(str)\n",
    "        DX_df['DX_TYPE'] = DX_df['DX_TYPE'].replace('09', '9')\n",
    "        DX_df['DX_TYPE'] = DX_df['DX_TYPE'].replace('9.0', '9')\n",
    "        DX_df['DX_TYPE'] = DX_df['DX_TYPE'].replace('10.0', '10')\n",
    "        \n",
    "        # we only care about code-related DX\n",
    "        DX_in_codes = []\n",
    "        for code_type in code_types:\n",
    "            DX_df_temp = DX_df[(DX_df.DX_TYPE == code_type) & (DX_df.DX.isin(code_dict[code_type]))]\n",
    "            DX_in_codes.append(DX_df_temp)\n",
    "            \n",
    "        DX_df = pd.concat(DX_in_codes, axis = 0)\n",
    "        \n",
    "        pat_ct_df = pat_df[pat_df.CENTER_NAME == ct_name]\n",
    "        pat_ct_df = pat_ct_df.merge(DX_df[['PATID', 'DX_DATE', 'DX', 'DX_TYPE', 'DAYS_SINCE_ADMIT']], \n",
    "                                    on = 'PATID', how = 'left')\n",
    "        \n",
    "        #drop rows do not involed in the codes\n",
    "        pat_ct_df.dropna(subset=['DX'], inplace = True)\n",
    "        \n",
    "        \n",
    "        # format time cols so that we can filter \"future\" dx later\n",
    "        if ct_name not in ct_missing_DX_DATE:\n",
    "            pat_ct_df['DX_DATE'] = pd.to_datetime(pat_ct_df['DX_DATE'], format = 'mixed')\n",
    "            pat_ct_df['DX_DATE'] = pat_ct_df['DX_DATE'].dt.strftime('%Y-%m-%d')\n",
    "            pat_ct_df['DX_DATE'] = pd.to_datetime(pat_ct_df['DX_DATE'], format = 'mixed')\n",
    "        else:\n",
    "            pat_ct_df.loc[:, 'DX_DATE'] = pat_ct_df.loc[:, 'ADMIT_DATE'] + \\\n",
    "            pd.to_timedelta(pat_ct_df.loc[:, 'DAYS_SINCE_ADMIT'], unit='D')\n",
    "\n",
    "        # require that it is \"history\", filter \"future\" dx\n",
    "        pat_ct_df = pat_ct_df[pat_ct_df.DX_DATE < pat_ct_df.ADMIT_DATE]\n",
    "        \n",
    "        # keep useful info\n",
    "        pat_ct_df = pat_ct_df[pat_id_cols]\n",
    "        processed_DX_dict[ct_name] = pat_ct_df\n",
    "        \n",
    "    return processed_DX_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:19<00:00, 19.01s/it]\n"
     ]
    }
   ],
   "source": [
    "enc_to_remove_DX_dict = get_enc_by_DX_code(DX_dict, onset_df, ESRD_dia_RRT_codes, ['9', '10'], pat_id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_to_remove_DX_all = concat_dfs_to_one(enc_to_remove_DX_dict)\n",
    "enc_to_remove_DX_all.drop_duplicates(inplace = True)\n",
    "# remove pat_id_cols matched rows from onset_df\n",
    "merged_df = onset_df.merge(enc_to_remove_DX_all, on=pat_id_cols, how='left', indicator=True)\n",
    "onset_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_dfs import read_procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/lideyi/AKI_GNN/notebooks/utils/read_dfs.py:234: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PX_df = pd.read_csv(data_path + \"AKI_PX.csv\", delimiter = ',', usecols = ['PATID', 'PX_DATE\"+PD.DATE_SHIFT\"', 'PX','PX_TYPE'])\n",
      "100%|██████████| 1/1 [00:11<00:00, 11.71s/it]\n"
     ]
    }
   ],
   "source": [
    "PX_dict = read_procedures(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return encounters related to the input code dict\n",
    "def get_enc_by_PX_code(PX_dict, pat_df, code_dict, code_types, pat_id_cols):\n",
    "    processed_PX_dict = dict()\n",
    "    \n",
    "    for ct_name, PX_df in tqdm(PX_dict.items()):\n",
    "        # format type\n",
    "        PX_df[['PATID', 'PX_TYPE', 'PX']] = PX_df[['PATID', 'PX_TYPE', 'PX']].astype(str)\n",
    "        PX_df['PX_TYPE'] = PX_df['PX_TYPE'].replace('09', '9')\n",
    "        PX_df['PX_TYPE'] = PX_df['PX_TYPE'].replace('9.0', '9')\n",
    "        PX_df['PX_TYPE'] = PX_df['PX_TYPE'].replace('10.0', '10')\n",
    "        \n",
    "        # we only care about code-related PX, after that we format time\n",
    "        PX_in_codes = []\n",
    "        for code_type in code_types:\n",
    "            PX_df_temp = PX_df[(PX_df.PX_TYPE == code_type) & (PX_df.PX.isin(code_dict[code_type]))]\n",
    "            PX_in_codes.append(PX_df_temp)\n",
    "            \n",
    "        PX_df = pd.concat(PX_in_codes, axis = 0)\n",
    "        \n",
    "        pat_ct_df = pat_df[pat_df.CENTER_NAME == ct_name]\n",
    "        pat_ct_df = pat_ct_df.merge(PX_df, on = 'PATID', how = 'left')\n",
    "        \n",
    "        #drop rows do not involed in the codes\n",
    "        pat_ct_df.dropna(subset=['PX'], inplace = True)\n",
    "        \n",
    "        \n",
    "        # format time cols so that we can filter \"future\" dx later\n",
    "        pat_ct_df['PX_DATE'] = pd.to_datetime(pat_ct_df['PX_DATE'], format = 'mixed')\n",
    "        pat_ct_df['PX_DATE'] = pat_ct_df['PX_DATE'].dt.strftime('%Y-%m-%d')\n",
    "        pat_ct_df['PX_DATE'] = pd.to_datetime(pat_ct_df['PX_DATE'], format = 'mixed')\n",
    "\n",
    "\n",
    "        # require that it is \"history\", filter \"future\" px\n",
    "        pat_ct_df = pat_ct_df[pat_ct_df.PX_DATE < pat_ct_df.ADMIT_DATE]\n",
    "        \n",
    "        # keep useful info\n",
    "        pat_ct_df = pat_ct_df[pat_id_cols]\n",
    "        processed_PX_dict[ct_name] = pat_ct_df\n",
    "        \n",
    "    return processed_PX_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.21s/it]\n"
     ]
    }
   ],
   "source": [
    "enc_to_remove_PX_dict = get_enc_by_PX_code(PX_dict, onset_df, ESRD_dia_RRT_codes, ['9', '10', 'CH'], pat_id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_to_remove_PX_all = concat_dfs_to_one(enc_to_remove_PX_dict)\n",
    "enc_to_remove_PX_all.drop_duplicates(inplace = True)\n",
    "# remove pat_id_cols matched rows from onset_df\n",
    "merged_df = onset_df.merge(enc_to_remove_PX_all, on=pat_id_cols, how='left', indicator=True)\n",
    "onset_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUMC: Patients with ESRD, dialysis and RRT excluded 261691\n"
     ]
    }
   ],
   "source": [
    "encounter_num_df = fill_in_encounter_num_df('Patients with ESRD, dialysis and RRT excluded', ct_names, onset_df, encounter_num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute eGFR and Filtered by SCr Baseline and eGFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate eGFR, based on SCr baseline\n",
    "def calculate_ckd_epi(row):\n",
    "    age = row['AGE']\n",
    "    gender = row['SEX']\n",
    "    race = row['RACE']\n",
    "    SCr = row['BASELINE_SCR']\n",
    "    \n",
    "    # Constants for the CKD-EPI formula\n",
    "    k = 0.7 if gender == 'F' else 0.9\n",
    "    alpha = -0.329 if gender == 'F' else -0.411\n",
    "    \n",
    "    # Calculate the eGFR\n",
    "    min_term = min(SCr / k, 1) ** alpha\n",
    "    max_term = max(SCr / k, 1) ** -1.209\n",
    "    age_term = 0.993 ** age\n",
    "    \n",
    "    # Gender and ethnicity adjustments\n",
    "    gender_term = 1.018 if gender == 'F' else 1\n",
    "    african_american_term = 1.159 if race == \"Black\" else 1\n",
    "    \n",
    "    eGFR = 141 * min_term * max_term * age_term * gender_term * african_american_term\n",
    "    \n",
    "    return eGFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_df['EGFR'] = onset_df.apply(calculate_ckd_epi, axis = 1)\n",
    "# Patients with SCr baseline > 3.5 mg/dL or eGFR < 15 mL/min/1.73 m^2 excluded \n",
    "onset_df = onset_df[(onset_df.EGFR > 15) & (onset_df.BASELINE_SCR < 3.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUMC: Patients with SCr baseline or eGFR out of range excluded 261691\n"
     ]
    }
   ],
   "source": [
    "encounter_num_df = fill_in_encounter_num_df('Patients with SCr baseline or eGFR out of range excluded', ct_names, onset_df, encounter_num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Sanity Check Before Merging with SCr DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Now we need to establish the prediction point for both AKI and non-AKI encounters for AKI encounters, we need to find the most severe AKI stage onset date, and the prediction point is just 24h before the onset date.  \n",
    "2. For non-AKI encounters, we need to find the middle SCr measurement date, and the prediction point is just 24h before the last SCr measurement date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the prediction target column, non-AKI = 0, AKI-1 = 1, AKI-2 = 2, AKI-3 = 3\n",
    "def set_AKI_target(row):\n",
    "    if pd.notna(row['AKI3_ONSET']):\n",
    "        return 3\n",
    "    elif pd.notna(row['AKI2_ONSET']):\n",
    "        return 2\n",
    "    elif pd.notna(row['AKI1_ONSET']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "onset_df['AKI_TARGET'] = onset_df.apply(set_AKI_target, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AKI_TARGET\n",
       "0    0.783917\n",
       "1    0.150353\n",
       "2    0.042608\n",
       "3    0.023123\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the percentage of each AKI stage\n",
    "AKI_stage_percentage = onset_df['AKI_TARGET'].value_counts(normalize=True).sort_index()\n",
    "AKI_stage_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most severe AKI stage onset date for each encounter\n",
    "def set_severe_AKI_onset_date(row):\n",
    "    if pd.notna(row['AKI3_ONSET']):\n",
    "        return row['AKI3_ONSET']\n",
    "    elif pd.notna(row['AKI2_ONSET']):\n",
    "        return row['AKI2_ONSET']\n",
    "    elif pd.notna(row['AKI1_ONSET']):\n",
    "        return row['AKI1_ONSET']\n",
    "    else:\n",
    "        return pd.NaT\n",
    "\n",
    "onset_df['AKI_ONSET_DATE'] = onset_df.apply(set_severe_AKI_onset_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_dfs import dup_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows before dropping dups:  261691\n",
      "# of rows after dropping dups:  261691\n"
     ]
    }
   ],
   "source": [
    "# dups check\n",
    "dup_check(onset_df, pat_id_cols)\n",
    "# assert AKI_ONSET_DATE between ADMIT_DATE and DISCHARGE_DATE\n",
    "AKI_onset_encounters = onset_df[onset_df.AKI_ONSET_DATE.notna()]\n",
    "assert (AKI_onset_encounters['AKI_ONSET_DATE'] >= AKI_onset_encounters['ADMIT_DATE']).all()\n",
    "assert (AKI_onset_encounters['AKI_ONSET_DATE'] <= AKI_onset_encounters['DISCHARGE_DATE']).all()\n",
    "#each center row number above zero\n",
    "for ct_name in ct_names:\n",
    "    assert(len(onset_df[onset_df.CENTER_NAME == ct_name]) > 0)\n",
    "# check two label columns match with each other\n",
    "assert onset_df.AKI_ONSET_LABEL.sum() == len(onset_df[onset_df.AKI_TARGET > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read SCr DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_dfs import read_and_format_SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.11s/it]\n",
      "100%|██████████| 1/1 [05:01<00:00, 301.08s/it]\n"
     ]
    }
   ],
   "source": [
    "SCR_df = read_and_format_SCR(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only care about non-AKI encounters here since we will use 24h (deprecated. now 0h) \n",
    "# before the middle SCr measurement as prediciton points\n",
    "non_AKI_df = onset_df[onset_df.AKI_ONSET_LABEL == False].copy(deep = True)\n",
    "# merge on CENTER_NAME and PATID, then filtered by ADMIT_DATE and DISCHARGE_DATE\n",
    "non_AKI_SCR_df = non_AKI_df.merge(SCR_df[['CENTER_NAME', 'PATID', 'SPECIMEN_DATE', 'RESULT_NUM']], \n",
    "                                  on = ['CENTER_NAME', 'PATID'], how = 'left')\n",
    "non_AKI_SCR_df = non_AKI_SCR_df[(non_AKI_SCR_df.SPECIMEN_DATE >= non_AKI_SCR_df.ADMIT_DATE) & \n",
    "                                (non_AKI_SCR_df.SPECIMEN_DATE <= non_AKI_SCR_df.DISCHARGE_DATE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort based on pat_id_cols and SPECIMEN_DATE\n",
    "non_AKI_SCR_df.sort_values(pat_id_cols + ['SPECIMEN_DATE'], inplace=True)\n",
    "\n",
    "# group by pat_id_cols and get the last row of each group (last SCr measurement)\n",
    "non_AKI_last_SCR_df = non_AKI_SCR_df.groupby(pat_id_cols).last().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows before dropping dups:  205144\n",
      "# of rows after dropping dups:  205144\n",
      "Last SCr measuresment overlap with admission date rate:  0.0022472019654486606\n",
      "Last SCr measuresment overlap with discharge date rate:  0.8297586085871388\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "# we cannot check len(non_AKI_last_SCR_df) == len(non_AKI_df) since some encounters do not \n",
    "# have SCr measurements, for those we just ignore them since they will be dropped latter\n",
    "# check if there are any duplicates in the middle SCr measurements\n",
    "assert (len(non_AKI_last_SCR_df) <= len(non_AKI_df))\n",
    "dup_check(non_AKI_last_SCR_df, pat_id_cols)\n",
    "# rename the SPECIMEN_DATE column first\n",
    "non_AKI_last_SCR_df.rename(columns = {'SPECIMEN_DATE': 'LAST_SCR_DATE'}, inplace = True)\n",
    "# check how many encounters the middle SCr measurements were taken on the admission date\n",
    "print(\"Last SCr measuresment overlap with admission date rate: \",\n",
    "len(non_AKI_last_SCR_df[non_AKI_last_SCR_df.LAST_SCR_DATE == non_AKI_last_SCR_df.ADMIT_DATE]) / len(non_AKI_last_SCR_df))\n",
    "# check how many encounters the middle SCr measurements were taken on the discharge date\n",
    "print(\"Last SCr measuresment overlap with discharge date rate: \", \n",
    "len(non_AKI_last_SCR_df[non_AKI_last_SCR_df.LAST_SCR_DATE == non_AKI_last_SCR_df.DISCHARGE_DATE]) / len(non_AKI_last_SCR_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the non_AKI_last_SCR_df back to onset_df\n",
    "onset_df = onset_df.merge(non_AKI_last_SCR_df[pat_id_cols + ['LAST_SCR_DATE']], on = pat_id_cols, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those with missing AKI_ONSET_DATE and LAST_SCR_DATE\n",
    "onset_df = onset_df[onset_df.AKI_ONSET_DATE.notna() | onset_df.LAST_SCR_DATE.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert conditions for onset_df\n",
    "assert (onset_df[onset_df['AKI_ONSET_DATE'].notna()]['LAST_SCR_DATE'].isna()).all(), \"If AKI_ONSET_DATE is not NaT, LAST_SCR_DATE should be NaT\"\n",
    "assert (onset_df[onset_df['AKI_ONSET_DATE'].notna()]['AKI_TARGET'] > 0).all(), \"If AKI_ONSET_DATE is not NaT, AKI_TARGET should be > 0\"\n",
    "assert (onset_df[onset_df['AKI_ONSET_DATE'].notna()]['AKI_ONSET_LABEL'] == True).all(), \"If AKI_ONSET_DATE is not NaT, AKI_ONSET_LABEL should be True\"\n",
    "\n",
    "assert (onset_df[onset_df['AKI_ONSET_DATE'].isna()]['LAST_SCR_DATE'].notna()).all(), \"If AKI_ONSET_DATE is NaT, LAST_SCR_DATE should not be NaT\"\n",
    "assert (onset_df[onset_df['AKI_ONSET_DATE'].isna()]['AKI_TARGET'] == 0).all(), \"If AKI_ONSET_DATE is NaT, AKI_TARGET should be 0\"\n",
    "assert (onset_df[onset_df['AKI_ONSET_DATE'].isna()]['AKI_ONSET_LABEL'] == False).all(), \"If AKI_ONSET_DATE is NaT, AKI_ONSET_LABEL should be False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PREDICTION_POINT column: the 48h (24h leading time for physicians to make decisions) before the non-NaT date between AKI_ONSET_DATE and LAST_SCR_DATE\n",
    "# here we run min() first since it will automatically handle NaT\n",
    "onset_df.loc[:, 'PREDICTION_POINT'] = onset_df[['AKI_ONSET_DATE', 'LAST_SCR_DATE']].min(axis=1) - pd.Timedelta(days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set a observation window length of 2 days\n",
    "ob_window_len = 3\n",
    "onset_df.loc[:, 'OBSERVATION_WINDOW_START'] = onset_df['PREDICTION_POINT'] - pd.Timedelta(days=ob_window_len - 1)\n",
    "# here we track what is the length of the observation window that span exceeds the admission date\n",
    "onset_df.loc[:, 'OBSERVATION_WINDOW_TO_ADMIT'] = (onset_df['OBSERVATION_WINDOW_START'] - onset_df['ADMIT_DATE']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-0: 29.78%\n",
      "Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-1: 60.15%\n",
      "Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-2: 64.23%\n",
      "Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-3: 55.36%\n"
     ]
    }
   ],
   "source": [
    "AKI_0 = onset_df[onset_df['AKI_TARGET'] == 0]\n",
    "AKI_1 = onset_df[onset_df['AKI_TARGET'] == 1]\n",
    "AKI_2 = onset_df[onset_df['AKI_TARGET'] == 2]\n",
    "AKI_3 = onset_df[onset_df['AKI_TARGET'] == 3]\n",
    "window_pct_0 = (AKI_0['OBSERVATION_WINDOW_TO_ADMIT'] < 0).mean() * 100\n",
    "window_pct_1 = (AKI_1['OBSERVATION_WINDOW_TO_ADMIT'] < 0).mean() * 100\n",
    "window_pct_2 = (AKI_2['OBSERVATION_WINDOW_TO_ADMIT'] < 0).mean() * 100\n",
    "window_pct_3 = (AKI_3['OBSERVATION_WINDOW_TO_ADMIT'] < 0).mean() * 100\n",
    "\n",
    "print(f\"Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-0: {window_pct_0:.2f}%\")\n",
    "print(f\"Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-1: {window_pct_1:.2f}%\")\n",
    "print(f\"Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-2: {window_pct_2:.2f}%\")\n",
    "print(f\"Percentage of OBSERVATION_WINDOW_TO_ADMIT < 0 when AKI-3: {window_pct_3:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we require that the observation window (3 days) can only be missing in one day\n",
    "# |---ob_start---|---admit---|---ob_end---|---leading 24h---|---aki_onset---|\n",
    "# this automatically filter out community-acquired AKI encounters\n",
    "onset_df = onset_df[onset_df['OBSERVATION_WINDOW_TO_ADMIT'] >= -1].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AKI_TARGET\n",
       "0    0.863650\n",
       "1    0.097163\n",
       "2    0.023425\n",
       "3    0.015762\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the percentage of each AKI stage\n",
    "AKI_stage_percentage = onset_df['AKI_TARGET'].value_counts(normalize=True).sort_index()\n",
    "AKI_stage_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUMC: Only hospital-aquired AKI encounters 199149\n"
     ]
    }
   ],
   "source": [
    "# log the number of encounters\n",
    "encounter_num_df = fill_in_encounter_num_df('Only hospital-aquired AKI encounters', ct_names, onset_df, encounter_num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUMC: Encounters should be prior to 2020 169554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/51878489/ipykernel_1872028/3809767568.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 1 0 ... 0 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  onset_df_cleaned.loc[:, 'AKI_ONSET_LABEL'] = onset_df_cleaned.loc[:, 'AKI_ONSET_LABEL'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Select encouters that happened before 2020\n",
    "onset_df = onset_df[onset_df['DISCHARGE_DATE'].dt.year < 2020].copy(deep = True)\n",
    "encounter_num_df = fill_in_encounter_num_df('Encounters should be prior to 2020', ct_names, onset_df, encounter_num_df)\n",
    "# we have tested that multi-class classification performance is really low, thus we only keep binary classification,\n",
    "# that is we need to drop AKI_TARGET (4 classes) and keep AKI_ONSET_LABEL (binary)\n",
    "# drop columns that are not needed\n",
    "onset_df_cleaned = onset_df.drop(columns = ['EGFR', 'AKI1_ONSET', 'AKI2_ONSET', 'AKI3_ONSET', 'AKI_TARGET', \n",
    "                         'AKI_ONSET_DATE', 'LAST_SCR_DATE',  'OBSERVATION_WINDOW_TO_ADMIT'])\n",
    "onset_df_cleaned.loc[:, 'AKI_ONSET_LABEL'] = onset_df_cleaned.loc[:, 'AKI_ONSET_LABEL'].astype(int)\n",
    "# reset index\n",
    "onset_df_cleaned.reset_index(drop=True, inplace=True)\n",
    "# reorder columns\n",
    "onset_df_cleaned = onset_df_cleaned[['CENTER_NAME', 'PATID', 'ONSETS_ENCOUNTERID', 'ADMIT_DATE', 'DISCHARGE_DATE', \n",
    "                                     'AGE', 'SEX', 'RACE', 'BASELINE_SCR', 'OBSERVATION_WINDOW_START','PREDICTION_POINT', 'AKI_ONSET_LABEL']]\n",
    "# check whether the df has any NaN\n",
    "assert onset_df_cleaned.isna().sum().sum() == 0\n",
    "# save the cleaned onset_df\n",
    "onset_df_cleaned.to_csv('/blue/yonghui.wu/lideyi/AKI_GNN/raw_data/onset_df_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AKI_ONSET_LABEL\n",
       "0    0.862274\n",
       "1    0.137726\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_df_cleaned.AKI_ONSET_LABEL.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KUMC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total number of encounters</th>\n",
       "      <td>265222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age between 18 and 90</th>\n",
       "      <td>261691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients with ESRD, dialysis and RRT excluded</th>\n",
       "      <td>261691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patients with SCr baseline or eGFR out of range excluded</th>\n",
       "      <td>261691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only hospital-aquired AKI encounters</th>\n",
       "      <td>199149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Encounters should be prior to 2020</th>\n",
       "      <td>169554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      KUMC\n",
       "Total number of encounters                          265222\n",
       "Age between 18 and 90                               261691\n",
       "Patients with ESRD, dialysis and RRT excluded       261691\n",
       "Patients with SCr baseline or eGFR out of range...  261691\n",
       "Only hospital-aquired AKI encounters                199149\n",
       "Encounters should be prior to 2020                  169554"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encounter_num_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
